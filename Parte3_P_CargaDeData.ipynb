{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"http://alacip.org/wp-content/uploads/2014/03/logoEscalacip1.png\" width=\"500\"></center>\n",
    "\n",
    "\n",
    "<center> <h1>Curso: Introducción al Python</h1> </center>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "* Profesor:  <a href=\"http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/\" target=\"_blank\">Dr. José Manuel Magallanes, PhD</a> ([jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe))<br>\n",
    "    - Profesor del **Departamento de Ciencias Sociales, Pontificia Universidad Católica del Peru**.<br>\n",
    "    - Senior Data Scientist del **eScience Institute** and Visiting Professor at **Evans School of Public Policy and Governance, University of Washington**.<br>\n",
    "    - Fellow Catalyst, **Berkeley Initiative for Transparency in Social Sciences, UC Berkeley**.\n",
    "    \n",
    "    \n",
    "## Parte 3:  Carga de datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='beginning'></a>\n",
    "\n",
    "En esta sección veremos diversas opciones para cargar / colectar datos en Python:\n",
    "\n",
    "1. [Propietary software.](#part1) \n",
    "2. [Google Forms.](#part2) \n",
    "3. [Uso de APIs.](#part3) \n",
    "4. [Scrapeo de tablas.](#part4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "\n",
    "<a id='part1'></a>\n",
    "## Data de  propietary / common software\n",
    "\n",
    "La mejor recomendación es que sus datos esten almacenados en algun lugar de la web. Y si está en su computadora, que esté en la misma carpeta donde estás escribiendo el código. En nuestro caso, todo esta en Github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I using a file from the American National Election Studies (ANES). This is a rather big file, so let me select some variables (\"libcpre_self\",\"libcpo_self\",a couple of question pre and post elections asking respondents to place themselves on a seven point scale ranging from ‘extremely liberal’ to ‘extremely conservative’) and create a data frame with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsOfInterest=[\"libcpre_self\",\"libcpo_self\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a Stata file into pandas is quite easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkToFileDTA=\"https://github.com/escuela-alacip/introPython/raw/master/data/anes_timeseries_2012.dta\"\n",
    "\n",
    "dataStata=pd.read_stata(linkToFileDTA,columns=varsOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting an Excel file is also straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkToFileXLSX=\"https://github.com/escuela-alacip/introPython/raw/master/data/ElectricBus.xlsx\"\n",
    "dataExcel=pd.read_excel(linkToFileXLSX,0) # no need for '0'\n",
    "dataExcel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files are as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkToFileCSV=\"https://github.com/escuela-alacip/introPython/raw/master/data/mealSeattle.csv\"\n",
    "\n",
    "dataCSV=pd.read_csv(linkToFileCSV)\n",
    "dataCSV.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it is more fun opening several of these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where='https://github.com/escuela-alacip/introPython/raw/master/data/'\n",
    "\n",
    "allNames=[where+\"interview_1_2_p\"+str(i)+\".csv\" for i in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had access to the names, the let's make a list of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "allFiles=[]\n",
    "for filename in allNames:\n",
    "    allFiles.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do we have the data?\n",
    "allFiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concatenate these  files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(allFiles[0:4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing what we did:\n",
    "newOneFile=pd.concat(allFiles[0:4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge with last file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastQ_file=pd.read_csv(\"https://github.com/escuela-alacip/introPython/raw/master/data/interview_finalQ.csv\")\n",
    "newOneFile=newOneFile.merge(lastQ_file,left_on='interview', right_on='interview') # no real need if same keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result\n",
    "newOneFile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "## Collecting your ad-hoc data\n",
    "\n",
    "Let me assume you are collecting some data using [this](https://goo.gl/forms/f4m4zv41xBh5osrw1) **GoogleForm**. The answers to your form are saved in an spreadsheet, which you should publish as a CSV file. \n",
    "\n",
    "Then, you can read it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "link=''\n",
    "myData = pd.read_csv(link)\n",
    "\n",
    "# here it is:\n",
    "myData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "-----\n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "## Collecting data from APIs\n",
    "\n",
    "There are organizations, public and private, that have an open data policy that allows people to access their repositories dynamically. You can get that data in CSV format if available, but the data is always in  XML or JSON format, which are containers that store data in an *associative array* structure. Python's dictionaries are very useful in these situations, as they can keep the NOSQL structure better than data frames. Let me get the data about 9-1-1 Police reponses from Seattle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# where is it online?\n",
    "url = \"https://data.seattle.gov/resource/pu5n-trf4.json\"\n",
    "\n",
    "# Go for the data:\n",
    "response = requests.get(url)\n",
    "\n",
    "# If we got the data:\n",
    "if response.status_code == 200:\n",
    "    data911 = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can turn it easily into a pandas data frame:\n",
    "\n",
    "data911DF=pd.DataFrame(data911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you are...\n",
    "data911DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case of Twitter\n",
    "\n",
    "Social media offers rich textual information. In particular, **Twitter** offers an API (registration required) to get the data they have.\n",
    "\n",
    "Follow these steps:\n",
    "1. If you do not have a Twitter account, create one; use your Twitter username and password to access this [link](https://apps.twitter.com/).\n",
    "2. When you are there **Create a new App**. Just complete the basic info requested.\n",
    "3. When the App is created, look for the _Keys and Access Tokens_.\n",
    "4. Open a text editor (a simple one) and create a dictionary like this:  \n",
    "{\"consumer_key\": \"aaa\", \"access_token_secret\": \"bbb\", \"consumer_secret\": \"ccc\", \"access_token\": \"ddd\"}\n",
    "5. Save it as keysAPI.txt, it should be in the root folder for this course (where your codes are).\n",
    "\n",
    "If you did everything ok, the next codes will work:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# get the security info from file\n",
    "keysAPI = json.load(open('data/keysAPI.txt','r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if you have **tweepy**. You may need to install it via **pip**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# recovering security info\n",
    "consumer_key = keysAPI['consumer_key']\n",
    "consumer_secret = keysAPI['consumer_secret']\n",
    "access_token = keysAPI['access_token']\n",
    "access_token_secret = keysAPI['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using security info:\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api=tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True,parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the tweets from a user:\n",
    "\n",
    "tweets = api.user_timeline(screen_name = 'MashiRafael', count = 1000, include_rts = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTweet=tweets[0]\n",
    "\n",
    "for field in aTweet.keys():\n",
    "    print (field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTweet['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dict into a DF in pandas\n",
    "import pandas as pd\n",
    "correaTweets=pd.DataFrame({'textTweet':[t['text'] for t in tweets]})\n",
    "correaTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "## Collecting data by scraping\n",
    "\n",
    "We are going to get the data from a table from this [wikipage](https://en.wikipedia.org/wiki/List_of_freedom_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "# Location \n",
    "wiki=\"https://en.wikipedia.org/wiki/\" \n",
    "link = \"List_of_freedom_indices\" \n",
    "\n",
    "wikiLink=wiki+link\n",
    "# avoid rejection from server\n",
    "identification = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "# contact server\n",
    "wikiPage =get(wikiLink , headers=identification)\n",
    "# BS gets wikipedia page as html\n",
    "wikiSoup =BS(wikiPage.content ,\"html.parser\")\n",
    "# BS extracts the whole table (it is html) \n",
    "wikiTables=wikiSoup.findAll(\"table\",{\"class\":\"wikitable sortable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are there?\n",
    "len(wikiTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, I just pick the one I need:\n",
    "wikiTable=wikiTables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do you have:\n",
    "wikiTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is there, but in HTML format. In general, our table is composed of ROWS, so this command will get every row from the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRows=wikiTable.find_all('tr') #'tr' stands for table row, it is a TAG in HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headersHtml is simply the first row of the table\n",
    "headersHtml=allRows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we have:\n",
    "headersHtml # this is ONE element from allRows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just saw the headers, but they are still in HTML; let me use the tag 'th' (table header) to get those elements in _headersHtml_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headersHtml.find_all('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see a list of elements, each between the tags 'th' (using < or >). Each element in the list has the text of the header (and other elements). We just need the text, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headersList is a list with each headers' TEXT element:\n",
    "headersList=[header.get_text() for header in headersHtml.find_all('th')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voilà les titres:\n",
    "headersList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process should be followed to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be the data:\n",
    "rowsHtml=allRows[1:]  #... [1:] is omitting the Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see one of these:\n",
    "rowsHtml[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the table cell uses the **td** TAG, but we will not recover ONE row, but several rows, so we need to adapt the previous code for the headers in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some python beauty:\n",
    "# using 'td' \n",
    "rowsList=[[cell.get_text() for cell in row.find_all('td')] for row in rowsHtml]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsList[0:3] # a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame creation\n",
    "import pandas as pd\n",
    "\n",
    "# making a data frame from list of lists!\n",
    "pd.DataFrame(data=rowsList , columns=headersList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "**AUSPICIO**: \n",
    "\n",
    "* El desarrollo de estos contenidos ha sido posible gracias al grant del Berkeley Initiative for Transparency in the Social Sciences (BITSS) at the Center for Effective Global Action (CEGA) at the University of California, Berkeley\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.bitss.org/wp-content/uploads/2015/07/bitss-55a55026v1_site_icon.png\" style=\"width: 200px;\"/>\n",
    "</center>\n",
    "\n",
    "* Este curso cuenta con el auspicio de:\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.python.org/static/img/psf-logo@2x.png\" style=\"width: 500px;\"/>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "**RECONOCIMIENTO**\n",
    "\n",
    "\n",
    "EL Dr. Magallanes agradece a la Pontificia Universidad Católica del Perú, por su apoyo en la participación en la Escuela ALACIP.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://dci.pucp.edu.pe/wp-content/uploads/2014/02/Logotipo_colores-290x145.jpg\" style=\"width: 400px;\"/>\n",
    "</center>\n",
    "\n",
    "\n",
    "El autor reconoce el apoyo que el eScience Institute de la Universidad de Washington le ha brindado desde el 2015 para desarrollar su investigación en Ciencia de Datos.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://escience.washington.edu/wp-content/uploads/2015/10/eScience_Logo_HR.png\" style=\"width: 500px;\"/>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
